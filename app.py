import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound
from openai import OpenAI
import os
from dotenv import load_dotenv
import re
from pathlib import Path
import networkx as nx
import plotly.graph_objects as go
import numpy as np
import json

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# .env íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì„œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë°±ì—… ë°©ë²•)
if not os.getenv("OPENAI_API_KEY") and env_path.exists():
    try:
        with open(env_path, 'r', encoding='utf-8-sig') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()
    except Exception:
        pass

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key) if api_key else None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìœ íŠœë¸Œ ê°•ì˜ ìš”ì•½ ë° Q&A",
    page_icon="ğŸ“š",
    layout="wide"
)

st.title("ğŸ“š ìœ íŠœë¸Œ ê°•ì˜ ìš”ì•½ ë° Q&A")
st.markdown("ìœ íŠœë¸Œ ê°•ì˜ ì˜ìƒì˜ ìë§‰ì„ ê°€ì ¸ì™€ ìš”ì•½í•˜ê³ , ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'transcript' not in st.session_state:
    st.session_state.transcript = None
if 'summary' not in st.session_state:
    st.session_state.summary = None
if 'enhanced_summary' not in st.session_state:
    st.session_state.enhanced_summary = None
if 'video_id' not in st.session_state:
    st.session_state.video_id = None
if 'knowledge_graph' not in st.session_state:
    st.session_state.knowledge_graph = None

def extract_video_id(url):
    """ìœ íŠœë¸Œ URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([a-zA-Z0-9_-]{11})',
        r'youtube\.com\/watch\?.*v=([a-zA-Z0-9_-]{11})'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def get_transcript(video_id):
    """ìœ íŠœë¸Œ ë¹„ë””ì˜¤ì˜ transcript ê°€ì ¸ì˜¤ê¸°"""
    try:
        ytt_api = YouTubeTranscriptApi()
        transcript_data = ytt_api.fetch(video_id, languages=['ko', 'en'])
        transcript_list = transcript_data.to_raw_data()
        transcript_text = ' '.join([item['text'] for item in transcript_list])
        return transcript_text, None
    except TranscriptsDisabled:
        return None, "ì´ ì˜ìƒì—ëŠ” ìë§‰ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    except NoTranscriptFound:
        return None, "ì´ ì˜ìƒì—ëŠ” í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def summarize_transcript(transcript):
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ transcript ìš”ì•½"""
    if not client:
        return None, "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìœ íŠœë¸Œ ê°•ì˜ ì˜ìƒì˜ ìë§‰ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. ê°•ì˜ì˜ ì£¼ìš” ê°œë…, ì˜ˆì‹œ, í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ê°•ì˜ ìë§‰ì„ ìš”ì•½í•´ì£¼ì„¸ìš”. ê°•ì˜ì˜ ì£¼ìš” ê°œë…, í•µì‹¬ ë‚´ìš©, ì¤‘ìš”í•œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\n\n{transcript}"
                }
            ],
            temperature=0.7,
            max_tokens=2000
        )
        return response.choices[0].message.content, None
    except Exception as e:
        return None, f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def enhance_summary(summary, transcript):
    """ìš”ì•½ì´ ë¶€ì‹¤í•œ ê²½ìš° ë‚´ìš©ì„ ë³´ì¶©"""
    if not client:
        return None, "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìš”ì•½ì„ ê²€í† í•˜ê³ , ì›ë³¸ ìë§‰ì„ ì°¸ê³ í•˜ì—¬ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ë³´ì¶©í•´ì£¼ì„¸ìš”. ê´€ë ¨ ê°œë… ì„¤ëª…, êµ¬ì²´ì ì¸ ì˜ˆì‹œ, ì¶”ê°€ ì„¤ëª… ë“±ì„ í¬í•¨í•˜ì—¬ ë” ì™„ì„±ë„ ë†’ì€ ìš”ì•½ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ìš”ì•½ì„ ê²€í† í•˜ê³ , ì›ë³¸ ìë§‰ì„ ì°¸ê³ í•˜ì—¬ ë‚´ìš©ì„ ë³´ì¶©í•´ì£¼ì„¸ìš”:\n\n[í˜„ì¬ ìš”ì•½]\n{summary}\n\n[ì›ë³¸ ìë§‰ ì¼ë¶€]\n{transcript[:3000]}"
                }
            ],
            temperature=0.7,
            max_tokens=2500
        )
        return response.choices[0].message.content, None
    except Exception as e:
        return None, f"ë‚´ìš© ë³´ì¶© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def answer_question(question, summary):
    """ìš”ì•½ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€"""
    if not client:
        return None, "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    try:
        enhanced_context = st.session_state.enhanced_summary if st.session_state.enhanced_summary else summary
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê°•ì˜ ìš”ì•½ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ê°•ì˜ ìš”ì•½ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:\n\n[ê°•ì˜ ìš”ì•½]\n{enhanced_context}\n\n[ì§ˆë¬¸]\n{question}"
                }
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return response.choices[0].message.content, None
    except Exception as e:
        return None, f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def extract_knowledge_graph(transcript, summary):
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ Knowledge Graph ì¶”ì¶œ"""
    if not client:
        return None, "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    try:
        # ìš”ì•½ì´ ìˆìœ¼ë©´ ìš”ì•½ì„ ì‚¬ìš©, ì—†ìœ¼ë©´ transcript ì¼ë¶€ ì‚¬ìš©
        content = summary if summary else transcript[:5000]
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ Knowledge Graph ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ê°œë…(ì—”í‹°í‹°)ê³¼ ê·¸ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”. ê° ê´€ê³„ëŠ” 'source'(ì‹œì‘ ê°œë…), 'target'(ë ê°œë…), 'relation'(ê´€ê³„ ìœ í˜•)ìœ¼ë¡œ í‘œí˜„í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ Knowledge Graphë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í•µì‹¬ ê°œë…ê³¼ ê´€ê³„ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:\n\n{content}\n\nì‘ë‹µ í˜•ì‹:\n{{\n  \"entities\": [\"ê°œë…1\", \"ê°œë…2\", ...],\n  \"relations\": [\n    {{\"source\": \"ê°œë…1\", \"target\": \"ê°œë…2\", \"relation\": \"ê´€ê³„ìœ í˜•\"}},\n    ...\n  ]\n}}"
                }
            ],
            temperature=0.7,
            max_tokens=3000,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        return result, None
    except json.JSONDecodeError:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
        try:
            text = response.choices[0].message.content
            # ê°„ë‹¨í•œ íŒŒì‹± ì‹œë„
            entities = []
            relations = []
            # ê¸°ë³¸ì ì¸ ì¶”ì¶œ ë¡œì§
            return {"entities": entities, "relations": relations}, None
        except Exception as e:
            return None, f"Knowledge Graph íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    except Exception as e:
        return None, f"Knowledge Graph ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def build_networkx_graph(kg_data):
    """Knowledge Graph ë°ì´í„°ë¥¼ NetworkX ê·¸ë˜í”„ë¡œ ë³€í™˜"""
    G = nx.Graph()
    
    # ì—”í‹°í‹° ì¶”ê°€
    entities = kg_data.get("entities", [])
    for entity in entities:
        G.add_node(entity)
    
    # ê´€ê³„ ì¶”ê°€
    relations = kg_data.get("relations", [])
    for rel in relations:
        source = rel.get("source", "")
        target = rel.get("target", "")
        relation_type = rel.get("relation", "ê´€ë ¨")
        
        if source and target:
            G.add_edge(source, target, relation=relation_type)
    
    return G

def visualize_3d_graph(G):
    """NetworkX ê·¸ë˜í”„ë¥¼ 3Dë¡œ ì‹œê°í™”"""
    if len(G.nodes()) == 0:
        return None
    
    # 3D ë ˆì´ì•„ì›ƒ ìƒì„± (Spring layoutì„ 3Dë¡œ í™•ì¥)
    pos_2d = nx.spring_layout(G, k=2, iterations=50)
    
    # 2D ì¢Œí‘œë¥¼ 3Dë¡œ ë³€í™˜ (zì¶•ì€ ëœë¤ ë˜ëŠ” degree ê¸°ë°˜)
    pos_3d = {}
    for node in G.nodes():
        x, y = pos_2d[node]
        # zì¶•ì€ ë…¸ë“œì˜ ì—°ê²° ìˆ˜(degree)ì— ë¹„ë¡€
        z = G.degree(node) * 0.1
        pos_3d[node] = (x, y, z)
    
    # ì—£ì§€ ì¢Œí‘œ ì¶”ì¶œ
    edge_x = []
    edge_y = []
    edge_z = []
    for edge in G.edges():
        x0, y0, z0 = pos_3d[edge[0]]
        x1, y1, z1 = pos_3d[edge[1]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
        edge_z.extend([z0, z1, None])
    
    # ë…¸ë“œ ì¢Œí‘œ ì¶”ì¶œ
    node_x = [pos_3d[node][0] for node in G.nodes()]
    node_y = [pos_3d[node][1] for node in G.nodes()]
    node_z = [pos_3d[node][2] for node in G.nodes()]
    
    # ë…¸ë“œ í¬ê¸° (degree ê¸°ë°˜)
    node_sizes = [G.degree(node) * 10 + 10 for node in G.nodes()]
    
    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤
    edge_trace = go.Scatter3d(
        x=edge_x, y=edge_y, z=edge_z,
        mode='lines',
        line=dict(width=2, color='#888'),
        hoverinfo='none',
        showlegend=False
    )
    
    # ë…¸ë“œ íŠ¸ë ˆì´ìŠ¤
    node_trace = go.Scatter3d(
        x=node_x, y=node_y, z=node_z,
        mode='markers+text',
        marker=dict(
            size=node_sizes,
            color=node_sizes,
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="ì—°ê²° ìˆ˜"),
            line=dict(width=2, color='white')
        ),
        text=list(G.nodes()),
        textposition="middle center",
        textfont=dict(size=10, color='black'),
        hovertext=[f"{node}<br>ì—°ê²° ìˆ˜: {G.degree(node)}" for node in G.nodes()],
        hoverinfo='text',
        showlegend=False
    )
    
    # 3D ê·¸ë˜í”„ ìƒì„±
    fig = go.Figure(data=[edge_trace, node_trace])
    
    fig.update_layout(
        title="Knowledge Graph (3D)",
        scene=dict(
            xaxis=dict(title="X", showbackground=False),
            yaxis=dict(title="Y", showbackground=False),
            zaxis=dict(title="Z (ì—°ê²° ìˆ˜)", showbackground=False),
            bgcolor="white",
            camera=dict(
                eye=dict(x=1.5, y=1.5, z=1.5)
            )
        ),
        width=800,
        height=600,
        margin=dict(l=0, r=0, t=30, b=0)
    )
    
    return fig

# ì‚¬ì´ë“œë°” - URL ì…ë ¥
with st.sidebar:
    st.header("ğŸ“¥ ì˜ìƒ ì…ë ¥")
    url = st.text_input("ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="https://www.youtube.com/watch?v=...")
    
    if st.button("ìë§‰ ê°€ì ¸ì˜¤ê¸°", type="primary"):
        if not url:
            st.error("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            video_id = extract_video_id(url)
            if not video_id:
                st.error("ìœ íš¨í•œ ìœ íŠœë¸Œ URLì´ ì•„ë‹™ë‹ˆë‹¤.")
            else:
                st.session_state.video_id = video_id
                with st.spinner("ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                    transcript, error = get_transcript(video_id)
                    if error:
                        st.error(error)
                        st.session_state.transcript = None
                    else:
                        st.session_state.transcript = transcript
                        st.success("ìë§‰ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")
                        # ìš”ì•½ê³¼ ë³´ì¶© ìš”ì•½, Knowledge Graph ì´ˆê¸°í™”
                        st.session_state.summary = None
                        st.session_state.enhanced_summary = None
                        st.session_state.knowledge_graph = None

# ë©”ì¸ ì˜ì—­
if st.session_state.transcript:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“ ìë§‰ ë‚´ìš©")
        with st.expander("ìë§‰ ë³´ê¸°", expanded=False):
            st.text_area("", st.session_state.transcript, height=200, disabled=True, label_visibility="collapsed")
        
        # ìš”ì•½ ìƒì„±
        if not st.session_state.summary:
            if st.button("ğŸ“Š ìš”ì•½ ìƒì„±", type="primary"):
                with st.spinner("ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    summary, error = summarize_transcript(st.session_state.transcript)
                    if error:
                        st.error(error)
                    else:
                        st.session_state.summary = summary
                        st.success("ìš”ì•½ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ìš”ì•½ í‘œì‹œ
        if st.session_state.summary:
            st.header("ğŸ“‹ ìš”ì•½")
            st.markdown(st.session_state.summary)
            
            # ë‚´ìš© ë³´ì¶©
            col_enhance1, col_enhance2 = st.columns([1, 4])
            with col_enhance1:
                if st.button("âœ¨ ë‚´ìš© ë³´ì¶©", use_container_width=True):
                    with st.spinner("ë‚´ìš©ì„ ë³´ì¶©í•˜ëŠ” ì¤‘..."):
                        enhanced, error = enhance_summary(st.session_state.summary, st.session_state.transcript)
                        if error:
                            st.error(error)
                        else:
                            st.session_state.enhanced_summary = enhanced
                            st.success("ë‚´ìš©ì´ ë³´ì¶©ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            if st.session_state.enhanced_summary:
                st.header("âœ¨ ë³´ì¶©ëœ ìš”ì•½")
                st.markdown(st.session_state.enhanced_summary)
            
            # Knowledge Graph ìƒì„±
            st.divider()
            st.header("ğŸ•¸ï¸ Knowledge Graph")
            
            if not st.session_state.knowledge_graph:
                if st.button("ğŸ“Š Knowledge Graph ìƒì„±", type="primary"):
                    with st.spinner("Knowledge Graphë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        kg_data, error = extract_knowledge_graph(
                            st.session_state.transcript,
                            st.session_state.enhanced_summary or st.session_state.summary
                        )
                        if error:
                            st.error(error)
                        else:
                            st.session_state.knowledge_graph = kg_data
                            st.success("Knowledge Graphê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            if st.session_state.knowledge_graph:
                # Knowledge Graph ì •ë³´ í‘œì‹œ
                entities = st.session_state.knowledge_graph.get("entities", [])
                relations = st.session_state.knowledge_graph.get("relations", [])
                
                col_info1, col_info2 = st.columns(2)
                with col_info1:
                    st.metric("ì—”í‹°í‹° ìˆ˜", len(entities))
                with col_info2:
                    st.metric("ê´€ê³„ ìˆ˜", len(relations))
                
                # NetworkX ê·¸ë˜í”„ ìƒì„± ë° ì‹œê°í™”
                G = build_networkx_graph(st.session_state.knowledge_graph)
                
                if len(G.nodes()) > 0:
                    fig = visualize_3d_graph(G)
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # ê·¸ë˜í”„ ì •ë³´
                    with st.expander("ğŸ“‹ ê·¸ë˜í”„ ìƒì„¸ ì •ë³´", expanded=False):
                        st.write("**ì—”í‹°í‹° ëª©ë¡:**")
                        st.write(", ".join(entities[:20]) + ("..." if len(entities) > 20 else ""))
                        
                        st.write("**ê´€ê³„ ëª©ë¡:**")
                        for i, rel in enumerate(relations[:10]):
                            st.write(f"- {rel.get('source', '')} â†’ {rel.get('target', '')} ({rel.get('relation', '')})")
                        if len(relations) > 10:
                            st.write(f"... ì™¸ {len(relations) - 10}ê°œ ê´€ê³„")
                else:
                    st.warning("ìƒì„±ëœ Knowledge Graphì— ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.header("â“ Q&A")
        
        if st.session_state.summary:
            # ì§ˆë¬¸ ì…ë ¥
            question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì£¼ìš” ê°œë…ì€ ë¬´ì—‡ì¸ê°€ìš”?")
            
            if st.button("ë‹µë³€ ë°›ê¸°", type="primary", use_container_width=True):
                if question:
                    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        answer, error = answer_question(question, st.session_state.summary)
                        if error:
                            st.error(error)
                        else:
                            st.session_state.last_answer = answer
                            st.markdown("### ë‹µë³€")
                            st.markdown(answer)
                else:
                    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ì´ì „ ë‹µë³€ í‘œì‹œ
            if 'last_answer' in st.session_state:
                st.markdown("### ìµœê·¼ ë‹µë³€")
                st.markdown(st.session_state.last_answer)
        else:
            st.info("ë¨¼ì € ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")

else:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìœ íŠœë¸Œ URLì„ ì…ë ¥í•˜ê³  ìë§‰ì„ ê°€ì ¸ì˜¤ì„¸ìš”.")
    
    # API í‚¤ í™•ì¸
    if not os.getenv("OPENAI_API_KEY"):
        st.warning("âš ï¸ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

